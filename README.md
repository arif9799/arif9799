<h1 align = "center"> 
  
  _Hi there, I am Arif!_
</h1>

<br>
<br>
<br>
<br>

[![](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/arif-sarfaraz-waghbakriwala-9424a1225/)&emsp;&emsp;
[![](https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@arifwaghbakriwala97)&emsp;&emsp;
[![](https://img.shields.io/badge/Facebook-1877F2?style=for-the-badge&logo=facebook&logoColor=white)](https://www.facebook.com/arif.waghbakriwala.9)&emsp;&emsp;
[![](https://img.shields.io/badge/Discord-7289DA?style=for-the-badge&logo=discord&logoColor=white)](https://discord.com/channels/arif97)&emsp;&emsp;
[![](https://img.shields.io/badge/YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://www.youtube.com/@ArifWaghbakriwala/featured)&emsp;&emsp;
[![](https://img.shields.io/badge/Pinterest-%23E60023.svg?&style=for-the-badge&logo=Pinterest&logoColor=white)](https://in.pinterest.com/arifwaghbakriwala/)&emsp;&emsp;
[![](https://img.shields.io/badge/-LeetCode-FFA116?style=for-the-badge&logo=LeetCode&logoColor=black)](https://leetcode.com/arif_wb/)&emsp;&emsp;
<br>
<br>
<br>
<br>


<!--SOON TO PUT PERSONAL GIF-->
<!------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ -->
<h1> 
  
  _Snapshot... Me, Myself!_ </h1>
<br>
  


<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/SnapShot2.gif" width="250" alt="Description">
</p>

üëã Hi everyone,

I'm Arif, a Data Scientist with a Master's in Data Science from Northeastern University. üöÄ My expertise lies in transforming complex datasets into actionable insights and crafting end-to-end business solutions. üß† I specialize in automating decision-making through innovative modeling techniques and I excel at unraveling untold data stories and presenting complex concepts in creative ways, including animations! üìä‚ú®

I've tackled impactful projects at PUMA North America, automating outlier detection in retail sales data and building sales and demand forecasting system for optimizing raw materials inventory. üíº üéì I also served as a Graduate Teaching Assistant for CS7150-Deep Learning and DS4400- Machine Learning and Data Mining, designing homeworks & rubrics, grading and conducting Office Hours to Simplify concepts.

My technical strengths include Time Series Analysis, Machine Learning, Data Mining, SQL and Statistics. Proficient in Python, R, C/C++ and key libraries like Pandas, Scikit-learn, Numpy, Tensorflow, PyTorch, Keras, etc üìöüñ•Ô∏è. üó£Ô∏èüìö Let's connect and explore the world of data together! üåê‚ú®




<br>
<br>
<br>
<br>



<!------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ -->
<h1> 
  
  _In the Pages of My Journey!_ </h1>
<br>


<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/AboutMe2.gif" width="250" alt="Description">
</p>

Surfing through the internet for a Data Scientist only to stumble upon this ![Portfolio](https://img.shields.io/badge/Portfolio-%23000000.svg?style=for-the-badge&logo=firefox&logoColor=#FF7139), a coincidence? Nah! You‚Äôve landed just in right place. Myself Arif, a Data Scientist & an ML Enthusiast with a passion for automation & zeal to craft solutions that requires minimal or no effort eradicating human intervention. I love fiddling around Datasets, exploring relations, extracting significant insights, retrieving never-heard-before stories, scrutinizing data not only to the point where all WHYs have been answered but uprooting causes to problems one never knew existed in first place, leveraging them to train apt ML algorithms to be able to tackle challenges similar to or even better then humans.üìäüîç

Fueled by passion for this domain, preparing myself for an extended progressive career that provides ample opportunities for constantly growing & learning in the field. Ever since my first encounter of stunning capabilities of AI, that triggered the course of events of my life- inducing me to pursue Data Science specializing in ML & Deep Learning, I‚Äôve been awe-struck every single time comprehending working mechanism of the feats achieved in this field, which seems creativity is fused with math wherein numbers tend to be more reliable then human instincts & have a greater impact in making decisions.ü§ñüìà

I hold a Masters Degree in Data Science at [__Northeastern University - Khoury College of Computer Sciences__](https://www.khoury.northeastern.edu/) and a Bachelor's Degree in Computer Engineering at [__Gujarat Technological University - Pacific School of Engineering__](https://www.gtu.ac.in). I am an experienced Data Scientist that can build end-to-end Data Science and Machine Learning Projects. Furthermore, I have a strong practical and theoretical experience in the development of Machine Learning, Deep Learning and AI Models.üéìüíª

I worked at companies such as [__PUMA North America__](https://us.puma.com/us/en) and [__Khoury College of Computer Sciences__](https://www.khoury.northeastern.edu/) as a __Data Scientist__ and __Graduate Teaching Assistant__, generating valuable information, insights and conclusion from data and contributing field knowledge to the peers and fellow students of Northeastern. This portfolio demonstrates a wide range of skills that I possess in solving and tackling machine learning problems and is a proof of my work of contribution to the field of Data Science.üìöüí°
<br>
<br>
<br>
<br>

<!------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ -->
<h1>
  
  _Skills!_ </h1>
<br>

<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/skillsstart.gif" width="250" alt="Description">
</p>
<br>

The following fragments of tools and technologies along with essentials, define my Capabilities and go-to stack for solving Data Science Problem
<br>


| Code/ Cloud Mastery | Frameworks/ Packages/ Libraries | Familiar Libraries/ Softwares | IDEs/ Version Control | I contribute to | Proficient in Tools |
| --- | --- | --- | --- | --- | --- |
| ![Azure](https://img.shields.io/badge/azure-%230072C6.svg?style=for-the-badge&logo=microsoftazure&logoColor=white) <br> ![Python](https://img.shields.io/badge/Python-FFD43B?style=for-the-badge&logo=python&logoColor=darkgreen) <br> ![SQL](https://img.shields.io/badge/SQL-005C84?style=for-the-badge&logo=sql&logoColor=white) <br> ![MySQL](https://img.shields.io/badge/MySQL-000000?style=for-the-badge&logo=mysql&logoColor=white) <br> ![R](https://img.shields.io/badge/R-276DC3?style=for-the-badge&logo=r&logoColor=white) <br> ![YAML](https://img.shields.io/badge/yaml-%23ffffff.svg?style=for-the-badge&logo=yaml&logoColor=151515) <br> ![C](https://img.shields.io/badge/C-00599C?style=for-the-badge&logo=c&logoColor=white) <br> ![C++](https://img.shields.io/badge/C%2B%2B-00599C?style=for-the-badge&logo=c%2B%2B&logoColor=white) <br> ![Java](https://img.shields.io/badge/Java-ED8B00?style=for-the-badge&logo=openjdk&logoColor=white) | <!--2nd Column--> ![Numpy](https://img.shields.io/badge/Numpy-777BB4?style=for-the-badge&logo=numpy&logoColor=white) <br> ![Pandas](https://img.shields.io/badge/Pandas-2C2D72?style=for-the-badge&logo=pandas&logoColor=white) <br> ![sklearn](https://img.shields.io/badge/scikit_learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white) <br> ![Tensorflow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=TensorFlow&logoColor=white) <br> ![Keras](https://img.shields.io/badge/Keras-FF0000?style=for-the-badge&logo=keras&logoColor=white) <br> ![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white) <br> ![Darts](https://img.shields.io/badge/darts-%230175C2.svg?style=for-the-badge&logo=darts&logoColor=white) <br> ![SciPy](https://img.shields.io/badge/SciPy-654FF0?style=for-the-badge&logo=SciPy&logoColor=white) <br> ![Plotly](https://img.shields.io/badge/Plotly-239120?style=for-the-badge&logo=plotly&logoColor=white) <br> ![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black) <br> ![OpenCV](https://img.shields.io/badge/opencv-%23white.svg?style=for-the-badge&logo=opencv&logoColor=white) | <!--3rd Column--> ![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white) <br> ![Kubernetes](https://img.shields.io/badge/kubernetes-%23326ce5.svg?style=for-the-badge&logo=kubernetes&logoColor=white) <br> ![Power Bi](https://img.shields.io/badge/power_bi-F2C811?style=for-the-badge&logo=powerbi&logoColor=black) <br> ![OpenGL](https://img.shields.io/badge/OpenGL-%23FFFFFF.svg?style=for-the-badge&logo=opengl) <br> ![mlflow](https://img.shields.io/badge/mlflow-%23d9ead3.svg?style=for-the-badge&logo=numpy&logoColor=blue) <br> ![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white) <br> ![Selenium](https://img.shields.io/badge/Selenium-43B02A?style=for-the-badge&logo=Selenium&logoColor=white) <br> ![MicrosoftSQLServer](https://img.shields.io/badge/Microsoft%20SQL%20Server-CC2927?style=for-the-badge&logo=microsoft%20sql%20server&logoColor=white) <br> ![Flask](https://img.shields.io/badge/flask-%23000.svg?style=for-the-badge&logo=flask&logoColor=white)| <!--4th Column--> ![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white) <br> ![Colab](https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&logo=googlecolab&color=525252) <br> ![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white) <br> ![Conda](https://img.shields.io/badge/conda-342B029.svg?&style=for-the-badge&logo=anaconda&logoColor=white) <br> ![VSCode](https://img.shields.io/badge/VSCode-0078D4?style=for-the-badge&logo=visual%20studio%20code&logoColor=white) <br> ![Notepad++](https://img.shields.io/badge/Notepad++-90E59A.svg?style=for-the-badge&logo=notepad%2B%2B&logoColor=black) <br> ![PyCharm](https://img.shields.io/badge/PyCharm-000000.svg?&style=for-the-badge&logo=PyCharm&logoColor=white) <br> ![RStudio](https://img.shields.io/badge/RStudio-75AADB?style=for-the-badge&logo=RStudio&logoColor=white)| <!--5th Column--> ![LeetCode](https://img.shields.io/badge/LeetCode-000000?style=for-the-badge&logo=LeetCode&logoColor=#d16c06) <br> ![Hackerrank](https://img.shields.io/badge/-Hackerrank-2EC866?style=for-the-badge&logo=HackerRank&logoColor=white) <br> ![Kaggle](https://img.shields.io/badge/Kaggle-035a7d?style=for-the-badge&logo=kaggle&logoColor=white) <br> ![Quora](https://img.shields.io/badge/Quora-%23B92B27.svg?style=for-the-badge&logo=Quora&logoColor=white) <br> ![Reddit](https://img.shields.io/badge/Reddit-%23FF4500.svg?style=for-the-badge&logo=Reddit&logoColor=white) <br> ![Stack Exchange](https://img.shields.io/badge/StackExchange-%23ffffff.svg?style=for-the-badge&logo=StackExchange) <br> ![Stack Overflow](https://img.shields.io/badge/-Stackoverflow-FE7A16?style=for-the-badge&logo=stack-overflow&logoColor=white)| <!--6th Column--> ![Linux](https://img.shields.io/badge/Linux-FCC624?style=for-the-badge&logo=linux&logoColor=black) <br> ![macOS](https://img.shields.io/badge/mac%20os-000000?style=for-the-badge&logo=macos&logoColor=F0F0F0) <br> ![Windows](https://img.shields.io/badge/Windows-0078D6?style=for-the-badge&logo=windows&logoColor=white) <br> ![Microsoft_Excel](https://img.shields.io/badge/Microsoft_Excel-217346?style=for-the-badge&logo=microsoft-excel&logoColor=white) <br> ![Microsoft_Word](https://img.shields.io/badge/Microsoft_Word-2B579A?style=for-the-badge&logo=microsoft-word&logoColor=white) <br> ![Microsoft_PowerPoint](https://img.shields.io/badge/Microsoft_PowerPoint-B7472A?style=for-the-badge&logo=microsoft-powerpoint&logoColor=white) <br> ![Adobe](https://img.shields.io/badge/adobe-%23FF0000.svg?style=for-the-badge&logo=adobe&logoColor=white) <br> ![Markdown](https://img.shields.io/badge/markdown-%23000000.svg?style=for-the-badge&logo=markdown&logoColor=white) <br> ![LibreOffice](https://img.shields.io/badge/LibreOffice-%2318A303?style=for-the-badge&logo=LibreOffice&logoColor=white) <br> ![Overleaf](https://img.shields.io/badge/Overleaf-47A141?style=for-the-badge&logo=Overleaf&logoColor=white) <br> ![LaTeX](https://img.shields.io/badge/LaTeX-47A141?style=for-the-badge&logo=LaTeX&logoColor=white)|
<br>

 <p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/Skillsend.gif" width="250" alt="Description">
</p>

<br>
<br>
<br>
<br>





<!--
- Code and Cloud Mastery

  - ![Azure](https://img.shields.io/badge/azure-%230072C6.svg?style=for-the-badge&logo=microsoftazure&logoColor=white)
  - ![Python](https://img.shields.io/badge/Python-FFD43B?style=for-the-badge&logo=python&logoColor=darkgreen)
  - ![SQL](https://img.shields.io/badge/SQL-005C84?style=for-the-badge&logo=sql&logoColor=white)
  - ![MySQL](https://img.shields.io/badge/MySQL-000000?style=for-the-badge&logo=mysql&logoColor=white)
  - ![R](https://img.shields.io/badge/R-276DC3?style=for-the-badge&logo=r&logoColor=white)
  - ![YAML](https://img.shields.io/badge/yaml-%23ffffff.svg?style=for-the-badge&logo=yaml&logoColor=151515)
  - ![C](https://img.shields.io/badge/C-00599C?style=for-the-badge&logo=c&logoColor=white)
  - ![C++](https://img.shields.io/badge/C%2B%2B-00599C?style=for-the-badge&logo=c%2B%2B&logoColor=white)
  - ![Java](https://img.shields.io/badge/Java-ED8B00?style=for-the-badge&logo=openjdk&logoColor=white)
<br>
<br>

- Expertise in Frameworks, Packages and Libraries
  
  - ![Numpy](https://img.shields.io/badge/Numpy-777BB4?style=for-the-badge&logo=numpy&logoColor=white)
  - ![Pandas](https://img.shields.io/badge/Pandas-2C2D72?style=for-the-badge&logo=pandas&logoColor=white)
  - ![sklearn](https://img.shields.io/badge/scikit_learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
  - ![Tensorflow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=TensorFlow&logoColor=white)
  - ![Keras](https://img.shields.io/badge/Keras-FF0000?style=for-the-badge&logo=keras&logoColor=white)
  - ![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
  - ![Darts](https://img.shields.io/badge/darts-%230175C2.svg?style=for-the-badge&logo=darts&logoColor=white)
  - ![SciPy](https://img.shields.io/badge/SciPy-654FF0?style=for-the-badge&logo=SciPy&logoColor=white)
  - ![Plotly](https://img.shields.io/badge/Plotly-239120?style=for-the-badge&logo=plotly&logoColor=white)
  - ![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black)
  - ![OpenCV](https://img.shields.io/badge/opencv-%23white.svg?style=for-the-badge&logo=opencv&logoColor=white)
<br>
<br>

- Familiarity with Additional Software Packages
  
  - ![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)
  - ![Kubernetes](https://img.shields.io/badge/kubernetes-%23326ce5.svg?style=for-the-badge&logo=kubernetes&logoColor=white)
  - ![Power Bi](https://img.shields.io/badge/power_bi-F2C811?style=for-the-badge&logo=powerbi&logoColor=black)
  - ![OpenGL](https://img.shields.io/badge/OpenGL-%23FFFFFF.svg?style=for-the-badge&logo=opengl)
  - ![mlflow](https://img.shields.io/badge/mlflow-%23d9ead3.svg?style=for-the-badge&logo=numpy&logoColor=blue)
  - ![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white)
  - ![Selenium](https://img.shields.io/badge/Selenium-43B02A?style=for-the-badge&logo=Selenium&logoColor=white)
  - ![MicrosoftSQLServer](https://img.shields.io/badge/Microsoft%20SQL%20Server-CC2927?style=for-the-badge&logo=microsoft%20sql%20server&logoColor=white)
  - ![Flask](https://img.shields.io/badge/flask-%23000.svg?style=for-the-badge&logo=flask&logoColor=white)
<br>
<br>

- IDEs and Version Control
  
   - ![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)
   - ![Colab](https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&logo=googlecolab&color=525252)
   - ![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white)
   - ![Conda](https://img.shields.io/badge/conda-342B029.svg?&style=for-the-badge&logo=anaconda&logoColor=white)
   - ![VSCode](https://img.shields.io/badge/VSCode-0078D4?style=for-the-badge&logo=visual%20studio%20code&logoColor=white)
   - ![Notepad++](https://img.shields.io/badge/Notepad++-90E59A.svg?style=for-the-badge&logo=notepad%2B%2B&logoColor=black)
   - ![PyCharm](https://img.shields.io/badge/PyCharm-000000.svg?&style=for-the-badge&logo=PyCharm&logoColor=white)
   - ![RStudio](https://img.shields.io/badge/RStudio-75AADB?style=for-the-badge&logo=RStudio&logoColor=white)
<br>
<br>

- I contribute to

  - ![LeetCode](https://img.shields.io/badge/LeetCode-000000?style=for-the-badge&logo=LeetCode&logoColor=#d16c06)
  - ![Hackerrank](https://img.shields.io/badge/-Hackerrank-2EC866?style=for-the-badge&logo=HackerRank&logoColor=white)
  - ![Kaggle](https://img.shields.io/badge/Kaggle-035a7d?style=for-the-badge&logo=kaggle&logoColor=white)
  - ![Quora](https://img.shields.io/badge/Quora-%23B92B27.svg?style=for-the-badge&logo=Quora&logoColor=white)
  - ![Reddit](https://img.shields.io/badge/Reddit-%23FF4500.svg?style=for-the-badge&logo=Reddit&logoColor=white)
  - ![Stack Exchange](https://img.shields.io/badge/StackExchange-%23ffffff.svg?style=for-the-badge&logo=StackExchange)
  - ![Stack Overflow](https://img.shields.io/badge/-Stackoverflow-FE7A16?style=for-the-badge&logo=stack-overflow&logoColor=white)
<br>
<br>

-  Proficient in Essential Tools

   - ![Linux](https://img.shields.io/badge/Linux-FCC624?style=for-the-badge&logo=linux&logoColor=black)
   - ![macOS](https://img.shields.io/badge/mac%20os-000000?style=for-the-badge&logo=macos&logoColor=F0F0F0)
   - ![Windows](https://img.shields.io/badge/Windows-0078D6?style=for-the-badge&logo=windows&logoColor=white)
   - ![Microsoft_Excel](https://img.shields.io/badge/Microsoft_Excel-217346?style=for-the-badge&logo=microsoft-excel&logoColor=white)
   - ![Microsoft_Word](https://img.shields.io/badge/Microsoft_Word-2B579A?style=for-the-badge&logo=microsoft-word&logoColor=white)
   - ![Microsoft_PowerPoint](https://img.shields.io/badge/Microsoft_PowerPoint-B7472A?style=for-the-badge&logo=microsoft-powerpoint&logoColor=white)
   - ![Adobe](https://img.shields.io/badge/adobe-%23FF0000.svg?style=for-the-badge&logo=adobe&logoColor=white)
   - ![Markdown](https://img.shields.io/badge/markdown-%23000000.svg?style=for-the-badge&logo=markdown&logoColor=white)
   - ![LibreOffice](https://img.shields.io/badge/LibreOffice-%2318A303?style=for-the-badge&logo=LibreOffice&logoColor=white)
   - ![Overleaf](https://img.shields.io/badge/Overleaf-47A141?style=for-the-badge&logo=Overleaf&logoColor=white)
   - ![LaTeX](https://img.shields.io/badge/LaTeX-47A141?style=for-the-badge&logo=LaTeX&logoColor=white)
<br>
<br>

-->



<h1> 
  
  _Contribution Statistics!_ 
  </h1>
<br>
<p align="center">
    <a href="https://github.com/arif9799">
      <img src="https://github-readme-streak-stats.herokuapp.com/?user=arif9799&stroke=ffffff&background=1c1917&ring=0891b2&fire=0891b2&currStreakNum=ffffff&currStreakLabel=0891b2&sideNums=ffffff&sideLabels=ffffff&dates=ffffff&hide_border=true" alt="GitHub Repository" />
    </a>
    <a href="https://github.com/arif9799" align="left">
      <img src="https://github-readme-stats.vercel.app/api/top-langs/?username=arif9799&langs_count=10&title_color=0891b2&text_color=ffffff&icon_color=0891b2&bg_color=1c1917&hide_border=true&locale=en&custom_title=Top%20%Languages" alt="Top Languages" />
    </a>
</p>
  
  <br>

  <p align="center">
    <a href="https://leetcode.com/arif_wb/">
    <img src="https://leetcode-stats-six.vercel.app/api?username=arif_wb&theme=dark&hide=contributed" alt="LeetCode Statistics">
  </a>

</p>


<!------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ -->
<h1> 
  
  _Career Kaleidoscope!_ 
  </h1>
<br>
  
<h3>
  
  [__PUMA North America__](https://us.puma.com/us/en) - _Data Scientist July'22- December'22_
</h3>
<br>

<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/PUMA.gif" width="250" alt="Description">
</p>
<br>

<h4>
  
  _Successfully delivered and deployed two fully fledged ML Production Grade Projects, that are still in effect today!_
</h4>
<br>

<h5 align="center">
  SALES AND DEMAND FORECASTING
</h5>
<br>

<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/timeseries.gif" width="250" alt="Description">
</p>
<br>

  - _Introduction:_ As a Data Scientist at PUMA, I led a pivotal project focused on Statistical Modeling and Forecasting for Apparel Manufacturers. The objective was to enhance preparedness for unprecedented demands from strategic Clients.
    
  - _Problem Statement:_ PUMA, a major Apparel Manufacturer, faced challenges fulfilling weekly orders from Amazon due to unpredictable demands and raw material shortages. This led to huge potential annual losses off the tables. The primary hurdle was the inability to strategically stock raw materials, impacting timely order fulfillment.
    
  - _Approach:_ Given the automated nature of Amazon's orders, the project involved collecting and analyzing data on weekly orders from Amazon bots since 2019. The emphasis was on Machine Learning, Statistical Modeling, Predictive Analysis and Time Series techniques.
    
  - _Data Analysis and Cleaning:_ Detailed exploratory data analysis (EDA) identifying patterns and behaviors in orders. Categorical encoding and feature engineering were applied to handle the intricacies of product variability. The dataset, comprising 2M rows and 100k unique products, underwent meticulous cleaning, systematic time series imputation at regular intervals/frequency and filtering, inflating the number of observations to 12M, focusing on the top 2k revenue-generating products.
    
  - _Leveraging Time Series Models:_ Various time series models, including AutoRegressive, Moving Averages and Deep Learning models, were employed for Univariate & Multivariate Panel Data Time Series Modeling. The ensemble technique significantly improved accuracy, reducing RMSE by 34% from 54 to 20.
    
  - _Building and deploying ML Pipeline:_ The project culminated in an ML Pipeline orchestrated in Azure Synapse Analytics with feature stores, training scripts and model registries. The ML Pipeline retrieved semi-structured data from MSSQL Server, cleaned and synthesized it, and fed it into different models. The Ensemble Container aggregated predictions, resulting in precise forecasts. Key Performance Indicators (KPIs) were incorporated, and the entire prototype was well-documented. This project not only mitigated operational challenges for PUMA but also showcased my proficiency in data science methodologies, statistical modeling and successful deployment of ML solutions.

<br>
<br>

<h5 align="center">
  ANOMALY DETECTION
</h5>
<br>

<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/AnomalyDetection.gif" width="250" alt="Description">
</p>
<br>

  - _Introduction:_ This project centered on Statistical Modeling and Backtest Predictions. The goal was to automate the identification and rectification of outliers in retail sales data, enhancing the integrity of month-end analytical reports.
    
  - _Problem Statement:_ Addressing intermittent inactivity in PUMA's global retail store networks, the project aimed to resolve incomplete data transmissions and gaps in the centralized database. The manual identification and rectification of these gaps were hindered by the high volume and frequency of sales transactions.
  
  - _Approach:_ Utilizing Python's 'openpyxl' library, I automated Excel refreshes to fetch daily retail sales data. The data was then aggregated into hourly intervals, transforming irregular frequencies into a structured time series format. Rolling and expanding windows, utilizing numpy, pandas and ADTK, were employed for different statistics features.
  
  - _Model Training:_ The time series data was processed to standardize irregular transaction frequencies across stores. Statistical feature engineering involved rolling and expanding window techniques. Separate Univariate & Multivariate time series models for each rolling statistic were trained using ADTK and Scikit-learn. Models were validated and tested on an **80-20** split to ensure accuracy and reliability.
  
  - _Identifying Outliers:_ A discrepancy threshold was established for back-test predictions against actual data. A voting system across models was implemented to classify data points as anomalies. This process was extended to all retail stores, significantly improving anomaly detection precision.
  
  - _Results:_ The implemented framework reduced man-hours for identifying outliers by **60%**. Rigorous evaluation of Key Performance Indicators **(KPIs)** and hypothesis testing was conducted. Interfaces using tkinter were developed for result display, showcasing flagged outliers and identifying specific retail stores contributing to sales mismatches. The architecture was encapsulated using auto_py_to_exe for seamless execution on any system.
<br>
<br>


<h3>
  
  [__Khoury College of Computer Sciences__](https://www.khoury.northeastern.edu/) at Northeastern University - _Graduate TA Jan'22- December'22_
</h3>
<br>

<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/northeastern.gif" width="250" alt="Description">
</p>
<br>
<br>

- CS 7150: Deep Learning
  - The course curriculum needed enhancement to emphasize practical applications of Neural Network Theories including Diffusion and Large Language Models
  - Undertook the initiative to restructure the curriculum and create a more interactive learning environment by helping build the logistics and infrastructure.
  - Designed and implemented advanced homework assignments on topics like Transformers and Diffusion Models from scratch
  - Set up discussion panels on the latest AI research papers, invoking live discussions while fostering a **90%** increase in student participation.
  - The restructured curriculum resulted in students not only grasping theoretical concepts but also understanding their real-world relevance.
 
<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/gta.gif" width="250" alt="Description">
</p>
  
- DS 4400: ML & Data Mining
  - The course aimed to provide students with a comprehensive understanding of Data Science, Machine Learning and Advanced Predictive Analytics.
  - My role was integral to bridging theoretical knowledge with hands-on experience in building ML Models from scratch in Python
  - Simplified complex academic theories into simple laymen terms, translating them into tangible real-world applications
  - Guided students through experiential learning projects to provide a practical bridge between theory and application.
  - Contributed to comprehensive course coverage, ensuring a strong foundation in both theory and practice.
  - Students gained a robust understanding of the subject, applying theoretical knowledge to real-world scenarios successfully.
 
<br>
<br>
<br>
<br>
 

<!------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ -->
<h1> 
  
  _Alma Mater_ 
  </h1>
  <br>

<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/almamater.gif" width="250" alt="Description">
</p>

<h4>
    
  - [Khoury College of Computer Sciences, Northeastern University](https://www.northeastern.edu/): Masters of Science in Data Science
  - [Pacific School of Engineering, Gujarat Technological University](https://www.gtu.ac.in/): Bachelors of Engineering in Computer Engineering
  - [Radiant English Academy](https://www.radiant.edu.in/): High School
  - [Sanjeewan Vidyalaya](https://www.facebook.com/sanjeewanpanchgani/): Junior School
    
  </h4>
<br>
<br>
<br>
<br>

  
<!------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ -->
<h1> 
  
  _Project Portfolio: Crafting Solutions_ 
  </h1>

  The following section will showcase my skills further utilized in personal and curriculum Projects. I invite you to explore the github profile and readme files of the Projects for further information as this is just a short summary into the vast array of possibilities where my skills can be applied, post collaboration with SMEs. 
  <br>
  <br>

<!---------------------------------------------------------------------->
<p align="center">
  
  ___
</p>

<h3 align="center">
  
  [Visual Grounding, _Deep Learning_](https://github.com/arif9799/Deep-Learning-Computer-Vision---Visual-Grounding)
</h3>
<br>

<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/visualgrounding.gif" width="250" alt="Description">
</p>
<br>

_You speak, We'll find it!_

Used an API for accessing flickr30k dataset to extract entities of Annotation (B-box), Phrases & Images, assembling pipeline to extract, transform & collate from multiple data source. Then, Pre-calculated high level general representation embeddings of Images & Textual content using Pre-trained Vision Transformers & BERT respectively. Moved on to Build & train baseline Transformer Encoder-Decoder Model on concatenated embeddings of image and text, to predict B-boxes with 75% IoU achieving an accuracy of 58% that can significantly spot objects in images as described by corresponding context provided. Also, developed and experimented light-weight architectures like Textual-Encoder & Decoder, Vision-Encoder & Decoder and Decoder Only Network with equivalent performance that outperforms the baseline models.
<br>
<br>

<!---------------------------------------------------------------------->
<p align="center">
  
  ___
</p>
<h3 align="center">
  
  [Neural Style Transfer, _Deep Learning_](https://github.com/arif9799/Neural-Style-Transfer---Deep-Learning)
</h3>
<br>

<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/NeuralStyleTransfer.gif" width="250" alt="Description">
</p>
<br>

_The Canvas Conundrum: Imposing Style of an image onto Contents of another_

An endeavor of imposition of an artistic style image onto contents of another, employing Transfer Learning concept using pre-trained CNN Model VGG-19. Normalized Images, built content-style loss function & convolved through CNN (with frozen weights) while back-propagating summed loss to Noise Image. Also, performed Hyper-parameter Tuning to find optimal values of Learning Rates, '…ë' & 'Œ≤' (…ë,Œ≤ determine proportion of content & style to be injected) with 21% MSE Loss
<br>
<br>


<!---------------------------------------------------------------------->
<p align="center">
  
  ___
</p>
<h3 align="center">
  
  [Sentimental Recommendation System, _Unsupervised ML_](https://github.com/arif9799/Sentimental-Recommendation-System)
</h3>
<br>

<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/RecommendationSystem.gif" width="250" alt="Description">
</p>
<br>

_OpinioCraft: Unleashing Sentimental Insights through Unsupervised ML_

An unsupervised approach to mine opinions, thoughts and emotions based on the mathematical notion of the words that determines the sentiment of the reviews that are being processed to achieve results for recommendation. The principal focus is to retrieve user‚Äôs search query (Product & Category), based on which the user will be recommended top-n products from that category alone. The Underlying mechanism in simplest terms is to figure out the sentiments of the reviews either as positive or negative, followed by clustering unique items to decide top-k products based on higher average of connotation scores.
<br>
<br>


<!---------------------------------------------------------------------->
<p align="center">
  
  ___
</p>
<h3 align="center">
  
  [Feature Analysis, _Supervised ML_](https://github.com/arif9799/Feature-Analysis)
</h3>
<br>

<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/FeatureAnalysis.gif" width="250" alt="Description">
</p>
<br>

_RateVue: Decoding IMDb ‚Äì A Feature Alchemy_ 

Initialized with importing primary dataset of 45k+ records, merging it with secondary dataset to handle missing values of certain variables, then validating custom procedures focused on Data Wrangling, typecasting, pivoting erratic variables to Sparse Matrix and much more. Conducted Univariate Exploratory Data Analysis to explore relations among dependent and independent Variables. Trained the simple models namely Logistic Regression & kNN which outperformed complex ones such as Decision Tree & Random Forest.
<br>
<br>


<!---------------------------------------------------------------------->
<p align="center">
  
  ___
</p>
<h3 align="center">
  
  [Diabetic Classification, _Supervised ML_](https://github.com/arif9799/Diabetic-Classification)
</h3>
<br>

<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/DiabeticClassification.gif" width="250" alt="Description">
</p>
<br>

_InsuLens: Focusing Clarity in Diabetic Classification_ 

Cleaned and preprocessed anthropometric datasets with a whopping 1.8 million observations collected from 9 different states in India. Analyzed and performed hyperparameter tuning with 'Grid Search Cross Validation' to derive optimal Parameters for training the MultiLayer Perceptron Classifier to classify the Diabetics. Upsampled the minority class from the imbalanced dataset using SMOTE technique that drastically increased the accuracy of predicting diabetic class from 13% to an impressive 71.4%.
<br>
<br>


<!---------------------------------------------------------------------->
<p align="center">
  
  ___
</p>
<h3 align="center">
  
  [Product Sales Analysis, _Data Science_](https://github.com/arif9799/Sales-Analysis/blob/main/Sales_Analysis_Online_Store.ipynb)
</h3>
<br>

<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/SalesAnalysis.gif" width="250" alt="Description">
</p>
<br>

_DollaLlama: Wrangling Sales Data with Quirky Precision_ 

Coalesced 180k+ records of sales into a file, performed Data Wrangling & Mining and Feature Engineered Variables, Envisioned strategic analysis based on Month, Quantities, Revenue generated & best-sellers to drive product decisions and Analyzed consumer behavior pattern of sales & extrapolated items to recommend based on frequently bought together.Electronic Appliances Sales Data ‚Äì Exploratory Data Analysis Coalesced 180k+ records of sales into a file, performed Data Wrangling & Mining and Feature Engineered Variables, Envisioned strategic analysis based on Month, Quantities, Revenue generated & best-sellers to drive product decisions and Analyzed consumer behavior pattern of sales & extrapolated items to recommend based on frequently bought together.
<br>
<br>


<!---------------------------------------------------------------------->
<p align="center">
  
  ___
</p>
<h3 align="center">
  
  [Life Expectancy Prediction, _Data Science and Supervised ML_](https://github.com/arif9799/LIFE-EXPECTANCY-PREDICTION)
</h3>
<br>

<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/LifeExpectancy.gif" width="250" alt="Description">
</p>
<br>

_Tomorrow's Time, Today's Numbers: Life Expectancy in a Snap_ 

Forecasted life expectancy by constructing a Linear Regression Model on independent attributes of primary Dataset, with subsequent Feature Engineering of 5 Candidate Predictors & selection of 3 independent variables as Predictors for the Regression Model. Conclusion with Accomplishment an RMSE of 0.0095, exhausting all combination of predictors with response variable ‚ÄòLife Expectancy‚Äô.
<br>
<br>

<!---------------------------------------------------------------------->
<p align="center">
  
  ___
</p>
<h3 align="center">
  
  [GDP Visualisation, _Data Science and EDA_](https://github.com/arif9799/GDP-Visualisation)
</h3>
<br>

<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/GDPVisualisation.gif" width="250" alt="Description">
</p>
<br>

_Graphonomics: Crafting a Visual representation of Economic Growth_ 

Started with extraction of demographic economic data from ‚ÄòWorld Development Indicator‚Äô Datasets in WDI Package in ‚ÄòR‚Äô language and then Analyzed data by plotting time series graphs of the GDP of certain countries for last 6 decades and constructing a Mini-Poster to Contrast. Finally, Inferencing various peaks of GDP & correlations of the variables & made presumptions of ‚ÄúThe Great Recession‚Äù.
<br>
<br>
<br>
<br>



<!------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ -->
<h1> 
  
  _Medium Blogs: Turning Geek-Speak into Shakespeare, One Article at a Time._ 
  </h1>


<!---------------------------------------------------------------------->
<p align="center">
  
  ___
</p>
<h3 align="center">
  
  [Sentimental Recommendation System, _Opinion Mining_](https://medium.com/@arifwaghbakriwala97/review-based-recommendation-system-67d88e167b06)
</h3>
<br>

<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/MediumSentimentalRecSys.gif" width="250" alt="Description">
</p>
<br>

In this Article

<br>
<br>

<!---------------------------------------------------------------------->
<p align="center">
  
  ___
</p>
<h3 align="center">
  
  [Time Series Prediction Intervals, _since predictions alone are not enough_](https://medium.com/@arifwaghbakriwala97/time-series-prediction-intervals-1866545a5554)
</h3>
<br>

<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/Mediumtimeseriespredinterval.gif" width="250" alt="Description">
</p>
<br>

In this Article

<br>
<br>

<!---------------------------------------------------------------------->
<p align="center">
  
  ___
</p>
<h3 align="center">
  
  [Attention is not Enough, _RNNs to Transformers, the Journey!_](https://medium.com/@arifwaghbakriwala97/attention-is-not-enough-1571328511a5)
</h3>
<br>

<p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/MediumAttnNotEnough2.gif" width="250" alt="Description">
</p>
<br>

In this Article

<br>
<br>




<br>
<br>
<br>
<br>


<!------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ -->
<h1> 
  
  _Competencies: Because Juggling Chainsaws Wasn't on the Resume_ 
  </h1>
  <br>

  <p align="center">
  <img src="https://github.com/arif9799/arif9799/blob/main/gifs/juggling.gif" width="250" alt="Description">
</p>
<br>
  
- Leadership Skills
- Communication Skills
- Team Work
- Self Starter
- Problem-solving Skills
- Keen and Curios
- Time Management
- Problem Solving abilities


<br>
<br>
<br>
<br>


<!------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ -->
<h1> 
  
  _Resume_ 
  </h1>
  <br>
  




